{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dk22SdBzjCk7"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "!pip install visualkeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dependencies\n",
        "\n",
        "import os\n",
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "import cv2\n",
        "import visualkeras\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "%matplotlib inline\n",
        "SEED = 15\n",
        "BATCH_SIZE = 8"
      ],
      "metadata": {
        "id": "932HZwPVjJEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "BPHz5PsZxZkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# اسم الملف المضغوط الذي قمت برفعه\n",
        "zip_file_path = \"/content/archive.zip\"\n",
        "# المجلد الذي سيتم استخراج الملفات فيه\n",
        "extract_dir = 'extracted_files'\n",
        "\n",
        "# فتح الملف المضغوط واستخراج الملفات\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# عرض الملفات المستخرجة\n",
        "for file_name in os.listdir(extract_dir):\n",
        "    print(file_name)\n",
        "\n",
        "# فتح ملف Excel\n",
        "excel_file_path = os.path.join(extract_dir, 'labeling.xlsx')\n",
        "df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# عرض محتوى ملف Excel\n",
        "print(\"Excel File Contents:\")\n",
        "df.head()  # عرض أول 5 صفوف\n",
        "df['dosya'] = df['dosya'].str.replace(r'.*/fotolar/', '', regex=True)\n",
        "\n",
        "# عرض البيانات المعدلة\n",
        "df"
      ],
      "metadata": {
        "id": "YXAEkKBivPmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating main dataframe contains image paths and their classes.\n",
        "\n",
        "def create_images_list(path):\n",
        "    full_path = []\n",
        "    images = os.listdir(path)\n",
        "    for i in tqdm(images, desc = 'images' ):\n",
        "        full_path.append(os.path.join(path, i))\n",
        "\n",
        "    return full_path\n",
        "\n",
        "\n",
        "data_healthy = create_images_list('/content/extracted_files/healty/healty/')\n",
        "data_down = create_images_list('/content/extracted_files/downSyndorme/downSyndrome/')\n",
        "\n",
        "\n",
        "# look-up table\n",
        "disease_classes = {0:'healthy', 1 : 'down' }\n",
        "\n",
        "data_df = pd.concat([  pd.DataFrame({\"img\" : np.array(data_healthy) , \"label\": 0 }),\n",
        "                        pd.DataFrame({\"img\" : np.array(data_down) , \"label\": 1 }) ], ignore_index = True)\n",
        "data_df = shuffle(data_df).reset_index(drop = True)"
      ],
      "metadata": {
        "id": "QJKDdgbljSlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating random 4 sample from a dataframe\n",
        "\n",
        "\n",
        "def create_img_label_sample(data, index):\n",
        "\n",
        "    img = cv2.imread(data['img'][index])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    label = disease_classes[data_df['label'][index]]\n",
        "\n",
        "    return img, label\n",
        "\n",
        "\n",
        "def create_random_samples(data):\n",
        "\n",
        "    idx1,idx2,idx3,idx4 =np.random.permutation(data.shape[0])[:4]\n",
        "\n",
        "    fig, axs = plt.subplots(1,4, figsize = (12,5), dpi = 300)\n",
        "\n",
        "    img1, name1 = create_img_label_sample(data, idx1)\n",
        "    img2, name2 = create_img_label_sample(data, idx2)\n",
        "    img3, name3 = create_img_label_sample(data, idx3)\n",
        "    img4, name4 = create_img_label_sample(data, idx4)\n",
        "\n",
        "    axs[0].imshow(img1)\n",
        "    axs[0].set_title(name1)\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    axs[1].imshow(img2)\n",
        "    axs[1].set_title(name2)\n",
        "    axs[1].axis('off')\n",
        "\n",
        "    axs[2].imshow(img3)\n",
        "    axs[2].set_title(name3)\n",
        "    axs[2].axis('off')\n",
        "\n",
        "    axs[3].imshow(img4)\n",
        "    axs[3].set_title(name4)\n",
        "    axs[3].axis('off')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "OfXcOhL9js4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random samples\n",
        "\n",
        "create_random_samples(data_df)"
      ],
      "metadata": {
        "id": "5tyipB1Yj2T2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(data_df['img'], data_df['label'], test_size = 0.15,  random_state = SEED)\n",
        "\n",
        "print(\"train images: \", X_train.shape[0])\n",
        "print(\"test images: \", X_test.shape[0])"
      ],
      "metadata": {
        "id": "WXMVI355j7Jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_preprocessing(image, label):\n",
        "\n",
        "    img = tf.io.read_file(image)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, size = (250,250))\n",
        "    img = img/255.0\n",
        "\n",
        "    return img, label"
      ],
      "metadata": {
        "id": "qy_lSZdrj79o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating dataset loaders\n",
        "\n",
        "train_loader = tf.data.Dataset.from_tensor_slices(( X_train, y_train) )\n",
        "train_dataset = (train_loader.map(img_preprocessing).batch(BATCH_SIZE).shuffle(X_train.shape[0]).prefetch(BATCH_SIZE))\n",
        "\n",
        "test_loader = tf.data.Dataset.from_tensor_slices(( X_test, y_test) )\n",
        "test_dataset = (test_loader.map(img_preprocessing).batch(BATCH_SIZE).prefetch(BATCH_SIZE))"
      ],
      "metadata": {
        "id": "JJLQF_kbj-0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "In = Input(shape=(250, 250, 3))\n",
        "\n",
        "conv2 = Conv2D(32, 2, padding = 'same')(In)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = Activation('elu')(conv2)\n",
        "conv2 = MaxPooling2D(2)(conv2)\n",
        "\n",
        "conv2 = Conv2D(64, 2, padding = 'same')(conv2)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = Activation('elu')(conv2)\n",
        "conv2 = MaxPooling2D(2)(conv2)\n",
        "\n",
        "\n",
        "conv2 = Conv2D(128, 2, padding = 'same')(conv2)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = Activation('elu')(conv2)\n",
        "conv2 = MaxPooling2D(2)(conv2)\n",
        "\n",
        "\n",
        "conv2 = Conv2D(256, 2, padding = 'same')(conv2)\n",
        "conv2 = BatchNormalization()(conv2)\n",
        "conv2 = Activation('elu')(conv2)\n",
        "conv2 = MaxPooling2D(2)(conv2)\n",
        "pool = GlobalAveragePooling2D()(conv2)\n",
        "drop = Dropout(0.6)(pool)\n",
        "dense1 = Dense(64, activation = 'relu')(drop)\n",
        "dense1 = Dense(64, activation = 'relu')(dense1)\n",
        "Out = Dense(1, activation = 'sigmoid')(dense1)\n",
        "\n",
        "model = Model(inputs = In, outputs = Out)\n",
        "\n",
        "model.compile(optimizer  = tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics = ['accuracy','AUC','Precision','Recall'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-rjUHNA5kBRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting the model\n",
        "\n",
        "plt.figure(dpi = 100)\n",
        "visualkeras.layered_view(model, spacing = 50,  scale_z = 1, scale_xy = 2 , legend=True, type_ignore=[BatchNormalization, Activation, Dropout])"
      ],
      "metadata": {
        "id": "0IUsLeEdxuC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training\n",
        "\n",
        "my_callbacks = [EarlyStopping(monitor = 'loss', patience = 8, min_delta = 0.0001)]\n",
        "\n",
        "hist = model.fit(train_dataset, epochs = 100, verbose =1, callbacks = my_callbacks)"
      ],
      "metadata": {
        "id": "B_oazFHTx08D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,2, figsize = (12,5), dpi = 100)\n",
        "\n",
        "axs[0].grid(linestyle=\"dashdot\")\n",
        "axs[0].set_title(\"Train Set Accuracy\")\n",
        "axs[0].plot(hist.history['accuracy'])\n",
        "axs[0].set_xlabel(\"epochs\")\n",
        "axs[0].legend([\"Accuracy\"])\n",
        "\n",
        "\n",
        "axs[1].grid(linestyle=\"dashdot\")\n",
        "axs[1].set_title(\"Other Classification Metrics\")\n",
        "axs[1].plot(hist.history['auc'])\n",
        "axs[1].plot(hist.history['precision'])\n",
        "axs[1].plot(hist.history['recall'])\n",
        "axs[1].set_xlabel(\"epochs\")\n",
        "axs[1].legend([\"AUC\", \"Precision\", \"Recall\"])"
      ],
      "metadata": {
        "id": "w4LCDeeyx3vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set evaluation\n",
        "\n",
        "test_eval = model.evaluate(test_dataset)\n",
        "\n",
        "print('test accuracy : {0:.3f} %'.format(test_eval[1]*100))\n",
        "print('test auc : {0:.3f}'.format(test_eval[2]))\n",
        "print('test precision : {0:.3f}'.format(test_eval[3]))\n",
        "print('test recall : {0:.3f}'.format(test_eval[4]))"
      ],
      "metadata": {
        "id": "6C40jdURx9oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set prediction\n",
        "\n",
        "test_take1 =  test_dataset.take(-1)\n",
        "test_take1_ = list(test_take1)\n",
        "pred = model.predict(test_take1)\n",
        "pred_ = np.round(pred)\n",
        "\n",
        "y_test_take = []\n",
        "for x in range(len(test_take1_)):\n",
        "    y_test_take.extend(test_take1_[x][1].numpy())"
      ],
      "metadata": {
        "id": "FihsQTiyyAx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "\n",
        "report = classification_report(np.array(y_test_take), pred_)\n",
        "print(report)"
      ],
      "metadata": {
        "id": "EdeAFEJQyDnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wrkHqxFQyIDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}